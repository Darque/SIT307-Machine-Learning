file:: [SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf](../assets/SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf)
file-path:: ../assets/SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf

- 01-Introduction to machine learning
  hl-page:: 2
  ls-type:: annotation
  id:: 67bd2b54-31c4-43be-983d-83a0693219a1
  hl-color:: red
	- Deﬁning Machine Learning
	  ls-type:: annotation
	  hl-page:: 5
	  hl-color:: red
	  id:: 67bd2ccb-cb75-47ec-a96b-549c0275c6bb
	  collapsed:: true
		- The 1959 deﬁnition below makes Machine Learning (ML) seem like magic - “Field of study that gives computers the ability to learn without being explicitly programmed,” (Samuel 1959)
		  hl-stamp:: 1740451043374
		  hl-page:: 5
		  ls-type:: annotation
		  id:: 67bd2ce0-ce7a-4727-975b-867e67467178
		  hl-color:: green
		  collapsed:: true
			- As we explore further you will see ML is a set of tools to derive meaning from data. For now, here is another deﬁnition that describes ML in mathematical terms.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2cfd-26ad-4fe7-add0-6968a6b65f20
		- Machine Learning as an equation
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: red
		  id:: 67bd2d0b-2ec7-4b76-a5d1-29d2fb2c3b31
		  collapsed:: true
			- “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E,”(Mitchell 1997, p. 2)
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67bd2d18-d06f-41e6-ad65-3c98dec63137
			- This is an elaborated, perhaps overly complicated deﬁnition of how a computer program learns. It learns only when performance improves with experience. So, what is experience? It is the data that we provide for the machine to process.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d34-0398-47af-aeea-e0d50c681a64
			- Experience E, is the information the machine processes using the tasks T, to get closer to what you want to produce, the performance measure P. If the machine continues to perform the tasks but produces rubbish then it hasn’t learned.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d4a-825c-4f0c-8676-3af537459635
			- A machine can be said to learn if it can perform tasks on the information you supply, and react to the data to get results that get closer to a useful result over time.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d59-3982-4235-8c03-96b042b405b7
			- Consider how humans learn and make decisions. We analyse data, ﬁnd patterns and use those patterns to make decisions or to predict the outcome of future events. For example, if you buy a car, you might look up reviews, check the features of different models, think about how you want to use the car, take some test drives and then make a choice.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d6f-af49-4a29-b265-44f79d4bd57a
		- Too much data
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: red
		  id:: 67bd2d7b-61d5-4578-8694-82f00f6fd374
		  collapsed:: true
			- So why do we need ML? It is all about the volume of data available to us. There is so much information that we cannot make sense of it. It’s as though you have to choose the perfect vehicle for every person at Deakin. It would be a massive task to know what every person wants and needs and to add all the details of various models of vehicle in order to make good decisions.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d94-76f2-4c6d-aac4-37f53b44a9a6
			- Automated systems (ML) will learn from the data we give them and, importantly, respond to changes in the data they are given to produce useful results.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2da4-9bdd-4701-b40d-3e0ab6ede637
	- Real-world applications of machine learning
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: red
	  id:: 67bd2dbc-6873-46ba-8e71-16c650778f9f
	  collapsed:: true
		- Machine learning involves the use of computer algorithms to learn how to perform different tasks.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67bd2e6f-b9e0-4414-9d21-3837012880ee
		- Let’s look at a few examples where machine learning is being applied.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67bd2e77-8be8-4ef6-a563-ae6a68ac7f43
		- Robotics
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2e7e-cda9-43e0-b3d7-8a4decf97919
		  collapsed:: true
			- Robots are going to be our companions in the future. They will do our cleaning, cooking and vacuuming. They’ll do our reading, schedule tasks, remind us to take our medications and play our favourite song at just the right time and volume. Machine learning is a fundamental part of enabling robots to perform these activities.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: yellow
			  id:: 67bd2e85-c252-4211-9755-c003db86729a
			- Simultaneous Localization and Mapping (SLAM) uses data to ﬁnd routes for rescue robots. Check out this amazing demonstration of real-time mapping using the pulsing light of LIDAR.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: green
			  id:: 67bd2e95-6785-4b25-a595-7633682dd7cf
		- Computer vision
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2ea1-02df-4224-be72-22fa00ef80d5
		- Board Games
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2eb0-3021-4144-9f48-cd6fee280a58
		  collapsed:: true
			- Board games are one of the oldest applications of machine learning. There are many successful algorithms which play checkers and board games such as ‘Go’.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f3c-fa1f-43d1-8431-983814830f96
				- In March 2016; AlphaGo, the board-game-playing AI from Google’s DeepMind beat Korean Go Champion Lee Sedol 4-1. AlphaGo uses deep neural networks and Monte Carlo tree search.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f44-07f7-49c4-b1a7-a34560abf976
				- Watch this 3 minute trailer for the AlphaGo documentary. The win is a deﬁning moment in AI similar to when the computer, Deep Blue, beat Garry Kasparov at chess in 1996.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f4c-9621-4a83-aabe-9e98f2c8ad48
		- Voice Recognition
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2f58-b571-4942-b9a0-a7d9737b4b0b
		  collapsed:: true
			- Speech recognition and machine learning have experienced waves of major innovations through recent history. It has beneﬁted from advances in deep learning, as well as big data and is widely used in a variety of applications.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f5d-7adf-48cc-bac2-517595b38d88
			  collapsed:: true
				- Technologies such as Siri and Google Home are examples of this. Siri uses speech recognizer, natural language processing and text-to-speech techniques.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f65-3760-48bb-8427-0fc4e78cb708
			- The Australian Government Tax Ofﬁce now holds millions of voice prints to identify Australians.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f79-7b57-43fd-96fc-8ecab36d7e3a
			  collapsed:: true
				- Their voice is compared with a stored voiceprint which captures more than 140 unique physical and behavioural characteristics of a person such as length of the vocal tract and nasal passage, the size and shape of the larynx, pitch, cadence and accent. (Nott,2016)
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f7f-bda8-4f84-9fda-ea32b56703de
			- How would you go at recognising people by voice? How about a million people? This is where machine learning excels.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f8f-a15c-4069-b7b1-1636e5fba7a2
			  hl-stamp:: 1740451731673
		- Digit Recognition
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2fa6-7ee9-44c6-bf35-5cf0e7361f57
		  collapsed:: true
			- Digit Recognition is the task of reading in the images of handwritten numbers and letters and outputting its machine-encoded equivalent. Machine Learning methods (SVM and Deep Learning) have hit >99% accuracy for this task.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fb0-041c-4e26-8307-dda9c6bbe820
			- Other examples are detection of numberplates, printed numbers on bills, handwriting and CAPTCHA.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fba-3531-4bfe-b883-75356efb2db2
		- Other interesting applications
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2fcc-ce11-4bf7-8d65-612184a882c4
		  collapsed:: true
			- A wide variety of machine learning applications are related to:
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fd3-0562-468a-b5eb-3ed82402d7f1
				- healthcare analytics: diagnosis and prognosis
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2fd8-0444-4140-933a-5b4f2d3e4682
				- stock market prediction
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3028-0e8e-4c82-b2b6-b744b4235d7f
				- business analytics
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3031-50ac-469a-9a9d-5cc895eca6f6
				- facial recognition
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3039-3ba8-44c2-890f-c59fd1a171ac
	- Machine Learning steps
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: red
	  id:: 67bd3096-2ef5-4d39-afe7-6990447cb14a
	  collapsed:: true
		- Have you ever thought about how you learn to make decisions?
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67bd31b0-577f-4cb7-b98f-e9b36bf08914
		  collapsed:: true
			- Let’s assume that we have been asked to research a problem and make a decision. You must have access to information (data) from which you can learn. Once you have data, what do you do with it? Most people analyse the information to ﬁnd patterns and relationships. You make a decision based on your work. Finally, you evaluate the model. Did you make a good decision or could it have been better?
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67bd31bd-9ede-47c6-98c2-69aa798dc79a
			- Let’s look at each of these stages in more detail and relate them to ML.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67bd31ca-5877-43a0-a9ba-50a11fe2d61f
		- Step 1: Data Manipulation
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd31d2-ef84-445c-beea-5448e2389e56
		  collapsed:: true
			- This is a process of data preparation. ML usually uses the largest sets of data available.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd31e6-8d7f-41a2-83d5-6ebf61017014
			- **Data Acquisition** - The ﬁrst step in data manipulation, data acquisition is the process of sampling information that illustrates real world physical conditions with a predeﬁned measurement. Using our car example, you might measure engine size, number of doors, size of tyres etc.
			  hl-stamp:: 1740452384649
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd31f2-3ac7-4ff5-a1fe-f419e62c5f6a
			  hl-color:: green
			  collapsed:: true
				- The data acquired should be reliable for converting into digital numeric values that can be manipulated by a computer. Number of car doors is easy; style is less easy to deﬁne numerically.
				  ls-type:: annotation
				  hl-page:: 7
				  hl-color:: yellow
				  id:: 67bd3200-9935-4654-b08c-40b085453d1c
				  hl-stamp:: 1740452405405
			- **Data Cleaning** - Once the data is properly stored, any redundant, noisy, unusable parts of it should be trimmed. Data cleaning is a major step as real-world datasets are highly affected by noise, redundancy and missing values. We might delete any three-wheeled cars because they’re so unusual.
			  hl-stamp:: 1740452538876
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd320a-044d-4b0e-9c65-3779a83447b3
			  hl-color:: green
		- Step 2: Analytics
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd3212-76bd-4a2c-8133-7630598b321c
		  collapsed:: true
			- **Analytics** - The second main step in machine learning, analytics mainly involves ﬁnding relationships and correlations in the prepared data in order to design an accurate model based on that input data
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd321e-8864-4951-92ea-1fefb2c09dae
			  hl-color:: green
			- **Exploratory Data** - in addition, analysis is an approach for analysing datasets in order to summarise their main characteristics or features. Many exploratory data analysis methods use visual illustration of data, based on different features. Things like graphs, charts and tables make data easier to understand.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3266-7d7d-4677-be2f-491b98fec230
			  hl-color:: green
			- **Predictive Machine Learning** - the last stage of Analytics. It uses a variety of statistical techniques such as predictive modelling in order to build a classiﬁer or intelligent system for decision making. We will come back to these ideas over the next few weeks.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3295-4112-4fae-b4b6-2de597a404ba
			  hl-color:: green
		- Step 3: Evaluation and Visualisation
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd34e3-69d7-4a68-b222-291c72648548
		  collapsed:: true
			- The ﬁnal result of Analytics is an intelligent system or model. As the last step of ML design, we have to evaluate the performance of the system. “Did I choose the right car?”
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd3514-c3b1-441b-9e90-b07111221e98
			- Reﬁnement - if the quality and performance of the intelligent system does not achieve a satisfactory outcome, the Reﬁnement procedure is required and another round of data manipulation and analytics becomes necessary. Again, we will come back to these ideas as you move through the Unit.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3529-b57b-4a7a-8b2d-1a6c90548dbe
			  hl-color:: green
			- In this Unit we mainly focus on the Analytics step. However it will be necessary to use parts of the Data Manipulation step to build a model.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd3553-11a6-4e61-b497-5ae3b3e2c3e3
		- [:span]
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67bd31a3-f4f0-41c2-b966-e7a7634efcae
		  hl-type:: area
		  hl-stamp:: 1740452258386
	- Supervised learning overview
	  ls-type:: annotation
	  hl-page:: 8
	  hl-color:: red
	  id:: 67bd3586-fb82-4b23-b1a1-7e6a1051c161
	  collapsed:: true
		- The majority of practical ML uses supervised learning. This brief overview will give you a broad understanding of supervised learning. It’s an important concept and we’ll be going into much more detail in the up coming weeks.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67bd35ce-242a-468e-be77-42507955e8c7
		- **Supervised learning** - can be deﬁned as: learning a function (otherwise known as a model) from data to relate inputs to known outputs.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67bd35e2-9758-4e69-896c-54e397a8a38d
		  hl-color:: green
		  collapsed:: true
			- If the concept is unfamiliar it may take several different descriptions or deﬁnitions to make sense of the idea.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67bd3604-0974-4c8c-98c2-6c0f11522943
		- Supervised learning is trained
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd3612-02b5-49f8-a886-046bffc56225
		  collapsed:: true
			- One deﬁning characteristic of supervised learning is that datasets have relationships built in from the start.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd361b-62db-4883-9ebe-e293555bb23b
			  collapsed:: true
				- For example, if you have datasets on vehicles you know that most cars have four wheels while most bicycles have two. You could say that having two wheels is a function of being a bicycle (with some exceptions) and having four wheels is a function of being a car (with the exception of very rare three-wheeled cars like this Fuldamobil S-7).
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd362b-1271-4e88-95ac-6630700aefef
				- This makes it possible to train the algorithm. The machine learns using known relationships in the data.
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd37ae-cd24-4f43-8bf6-16ffb780f812
		- Training and evaluation data
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd37c1-e865-41b4-885e-f89f63e6b397
		  collapsed:: true
			- For supervised learning, training requires dividing the available data into **training data** and **evaluation data**. Most of the data is used to develop and train a function ‘model’. We know the relationship between the inputs and the outputs. In other words, we know the ‘right’ answers so we can select, manipulate and reﬁne features to train the machine. The more often the answer is correct, (ie. “This is a bicycle”), the closer you are to having a useful algorithm
			  hl-page:: 8
			  ls-type:: annotation
			  id:: 67bd37d8-2c7c-4699-b52f-d5a0cd74e10a
			  hl-color:: green
			  hl-stamp:: 1740453871080
				- The evaluation data can be used to test the model with fresh, unused input data.
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd37fb-134a-403a-a1d5-7afb8e476222
		- A mathematical deﬁnition
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd3806-84a9-4c89-91c5-8a1e7b45f006
		  collapsed:: true
			- Machine algorithms must be described mathematically. Remember that computers understand numbers so we must translate our questions into formulas or algorithms so they can process answers.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd382a-ef4a-45bc-92ba-4aa27f5f24bc
			- In **supervised learning**, the training data includes output information (labels/targets).
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: green
			  id:: 67bd3831-27d8-463b-9464-3c269ea72780
				- **Target function**: $𝑓: 𝑋 → 𝑌$
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3849-d21e-4b52-9c13-0abce8e2addb
				  hl-color:: green
				- **Examples**: It is in the form of $(𝑥, 𝑦)$, denoted as $(𝑥1, 𝑦1)$, . . . , $(𝑥𝑛, 𝑦𝑛)$.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd385e-3efd-44da-ae3d-d9ea4cd1f7df
				  hl-color:: green
				- **Hypothesis** $𝑔: 𝑋 → 𝑌$ such that $𝑔(𝑥) = 𝑓(𝑥)$.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3887-9233-4e15-aec8-18bca1b8ab0c
				  hl-color:: green
				- $x =$ set of attribute values (attribute-value representation)
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd38c9-bcf0-4806-82f2-d0a70536d01e
				  hl-color:: green
				- $y =$ a discrete label (*classiﬁcation*), a real valued number (*regression*).
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd38dd-bd3e-4ecc-b9cc-8235e3d8f725
				  hl-color:: green
		- Two types of supervised learning
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd38f8-af4e-4fc5-b8c5-ea4a397a1bec
		  collapsed:: true
			- 1.0 Classiﬁcation problems
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd39ae-68a5-4539-9568-46fcbc09ff89
				- **Decision boundaries** - in a supervised learning problem with two classes, decision boundaries are a hyper-surface that partitions data space into two sets, each of these sets represent one of the classes. In other words, you divide the data according to a trained algorithm.
				  hl-stamp:: 1740454342948
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd39ba-cedf-49d5-983c-a5f22c671470
				  hl-color:: green
				  collapsed:: true
					- Consider the following ﬁgure as an illustration of supervised learning.
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3a9f-9ff9-4567-9714-60a91f9d722e
					- As you can see on the left, in some less complex cases a linear decision boundary can solve the classiﬁcation problem. However as illustrated on the right, more complex cases, require complicated decision boundaries.
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3ae6-3c70-4527-b3cb-2a7fd9dcda64
					  hl-stamp:: 1740454637951
					- [:span]
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3ad3-9789-452c-8b8d-2c9156ae234f
					  hl-type:: area
					  hl-stamp:: 1740454609761
					- {{video https://youtu.be/nKW8Ndu7Mjw}}
			- 2.0 Regression problems
			  hl-page:: 8
			  ls-type:: annotation
			  id:: 67bd3f20-7a2b-4672-b343-d30e438c6c9c
			  hl-color:: blue
			  hl-stamp:: 1740455762211
				- **Regression** - Another example of supervised learning, is regression. The overall idea of regression is to examine the relationship between response variables and one or more predictor variables. This examination can result in a hyperplane, representing the regression analysis. The following ﬁgure, illustrates a regression problem in 2 dimensions.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3eff-f4cf-45f6-a155-6d6279de6051
				  hl-color:: green
				  collapsed:: true
					- [:span]
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3f68-b036-4d45-993c-3e02413bce6a
					  hl-type:: area
					  hl-stamp:: 1740455779706
	- Unsupervised learning overview
	  ls-type:: annotation
	  hl-page:: 9
	  hl-color:: red
	  id:: 67bd40c0-9595-405c-b61d-e15b7d119680
	  collapsed:: true
		- This brief introduction will give you an overview of the material we will cover in weeks 3 and 4.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd40fe-c010-4416-a7dc-504504de7421
		- The main question in unsupervised learning is *How do you ﬁnd the underlying structure of a dataset which is unlabelled?* How does an algorithm learn patterns from (unlabelled) data ($𝑥_{1}, . . . , 𝑥_{𝑛}).
		  hl-page:: 9
		  ls-type:: annotation
		  id:: 67bd422d-3bc9-4f1d-9fc4-e73d48d5b366
		  hl-color:: blue
		- In other words, can a machine algorithm learn from very large sets of data without additional information about the data? Can it ﬁnd patterns and relationships, make sense of data and make decisions or predictions?
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd4266-e232-4202-b020-d858981b4b21
		  collapsed:: true
			- For example, if you had lots of data on all the ways people move around a city: long trips, short trips, time of day, vehicle type, direction of travel etc in a mixed up dataset without labels, would machine learning be able to make sense of it and tell you when to leave home to get to work on time?
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd435a-5930-450f-bf46-6673d8b30d04
		- Popular approaches in unsupervised learning are:
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd4369-881d-4bf6-ac72-464b6fb23d37
		  hl-stamp:: 1740456815568
		  collapsed:: true
			- clustering (similarity-based), density estimation
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd4379-db90-47da-98c2-e849411007c3
			- factor analysis
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd4380-2e8a-4bad-9da4-e9f5ec89bac9
		- Clustering
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: red
		  id:: 67bd4394-9313-432d-987c-5d566c46749f
		  collapsed:: true
			- **Clustering** - is the process of grouping similar points together. The goal of this unsupervised machine learning technique is to ﬁnd relative similarities in the data points. But why do we need to perform this task? Because it will give us insight into underlying patterns or different groups within the dataset(s).
			  hl-page:: 9
			  ls-type:: annotation
			  id:: 67bd439c-76e5-46aa-8672-21d625d8e0eb
			  hl-color:: green
			  collapsed:: true
				- Let’s consider an example. The unlabelled data points (before clustering) are shown at the top of the following ﬁgure.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd43e1-610f-4a0f-99c3-a2d88133db9d
				  collapsed:: true
					- By performing clustering based on the similarities and correlations, we might ﬁnd 2 clusters in these data points. For example, we might determine trips around the city of less than 25 km and more than 25 km. This creates two groups. The art is in working out if 25 km is a good cut-off point. Is it useful? Perhaps it would be more useful to extract more clusters.
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd4444-933a-4178-8bb3-d5ab20b5647d
					- We can perform the clustering in a way that results in more than two clusters. Let’s say 3 or even 4 clusters. We might have a cluster of trips that are more than 1 km and less than 10 km. Then perhaps the machine might overlay that with a cluster of pedestrian data. Would that be useful? How could you make it better?
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd4458-4d89-46ef-8fc0-483177ffecf6
					- [:span]
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd43f4-847b-4c0e-a243-92ad12b52e58
					  hl-type:: area
					  hl-stamp:: 1740456947520
			- Since the data is **unlabelled** in clustering problems, based on the features and the **expectation of the user** from the behaviour of the data, we can look for any number of clusters.
			  hl-page:: 9
			  ls-type:: annotation
			  id:: 67bd4490-4c0d-46c1-9aef-afb06975b689
			  hl-color:: green
			  collapsed:: true
				- Say my expectation is that most trips in the city are less than 10 km. If the algorithm presents me with a cluster that contains trips of less than 15 metres, is that useful? It depends on what I’m trying to ﬁnd out. Perhaps I would change that parameter.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd44ac-1fcd-4f6a-9bf8-7ec67b620018
		- A real-world example
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: red
		  id:: 67bd44c9-efa8-497d-942a-f1d23fc111fe
		  collapsed:: true
			- The popular entertainment company Netﬂix opened a competition for the best collaborative ﬁltering algorithm to predict user ratings for ﬁlms. They provided a training data set of 100, 480, 507 movie ratings that 480, 189 users gave to 17, 770 movies.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: blue
			  id:: 67bd4503-47df-4a50-8995-57f39458b121
			  collapsed:: true
				- This competition was a real “Movie Recommendation Problem”. They were expecting contestants to predict movie ratings for users. The winning Bellkor solution won the small team 1 million dollars from Netﬂix. In such problems there are no labels available for data points. That is why we are categorizing such problems as unsupervised learning.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd451a-62f8-40fd-9c17-5c57ad06c82f
				- [:span]
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd452b-c899-4cd0-a387-9807979a7152
				  hl-type:: area
				  hl-stamp:: 1740457257296
			- Generally, the potential tasks for ML unsupervised learning are:
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: blue
			  id:: 67bd4536-3c00-459b-849a-cc61e098207b
				- information retrieval
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4543-2744-40dd-8697-9a52f598e0e4
				- data compression (reduction)
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd454b-266f-4e95-9ca8-f40a3247be94
				- anomaly detection
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4553-577e-4f59-9563-0fb976875b25
				- data understanding and visualization
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4559-f9ab-4a0e-a28d-63049b0808db
	- Reinforcement learning
	  ls-type:: annotation
	  hl-page:: 10
	  hl-color:: red
	  id:: 67bd5961-8c54-4163-a381-7a597df09084
	  collapsed:: true
		- Reinforcement learning is another important type of machine learning algorithm.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67bd596c-aabc-4e4f-af96-1e81f4732cbc
		- **Interactions** - in this algorithm, an agent learns how to behave in an environment by performing actions and learning from interactions. Learning from“interaction with the environment” replicates the way humans learn by instinct, curiosity and experimentation.
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67bd597a-026b-42d9-8073-d303501fe297
		  hl-color:: green
		  collapsed:: true
			- The learner (a machine or a human) acts on its environment, receives some evaluation based on its action (reward), but is not told which action is the correct one for a desired end goal. The learner’s actions affect the data it receives later.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67bd599c-b26c-425c-a0ee-fef2c2a46bc5
		- There are many logic games like Chess, with a sequence of decisions. It is possible to train an agent to learn how to play Chess by reinforcement learning; if the actions and the corresponding rewards are well deﬁned. For example, if I move my Queen out to a vulnerable square, it gets taken off the board. I lose. Next time I’ll try something different.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: yellow
		  id:: 67bd59b6-b735-43d4-9266-71a913f773ba
		- [:span]
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: yellow
		  id:: 67bd5a0f-5e8a-493e-9891-853dcef4acbb
		  hl-type:: area
		  hl-stamp:: 1740462605446
- Model evaluation and selection
  hl-page:: 11
  ls-type:: annotation
  id:: 67bd5a29-e7ae-4a59-bea6-223279755caf
  hl-color:: red
	- Model evaluation
	  hl-page:: 11
	  ls-type:: annotation
	  id:: 67bd5a53-3e15-4310-8fec-d5e2d37f6e1c
	  hl-color:: red
	  collapsed:: true
		- In machine learning problems, we should always evaluate a model to determine if it will do an excellent job of predicting the labels on new and future test data.
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: blue
		  id:: 67bd5a6c-2c78-4201-8855-9b274a470643
		- Because future instances have unknown label values, we need to check the accuracy of a machine learning model on test data with correct labels that we already know. We use this assessment as a proxy for predictive accuracy on future data (which is unknown to us!). For this purpose we need to:
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: blue
		  id:: 67bd5a7b-fb04-45ae-9e80-2402b910b690
			- randomly split examples into a **training dataset** and **test dataset**
			  hl-page:: 11
			  ls-type:: annotation
			  id:: 67bd5a89-e82a-4278-9fed-c85881186985
			  hl-color:: green
			- use the training dataset to **learn a model**
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: green
			  id:: 67bd5aa4-0ba3-49ce-844a-ccc7125df62a
			- **evaluate the model** using the test dataset and a measurement (such as the accuracy of prediction)
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: green
			  id:: 67bd5ab4-4567-4d87-8753-1357858fed70
			- repeat for different random splits and then **average the results**
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: green
			  id:: 67bd5ac6-759a-4887-ad18-6821993eeff7
			- check the accuracy of results and try again (iterate) until the model makes useful predictions
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67bd5ad5-3e3b-413c-9f0c-66e83bfd3626
			  hl-stamp:: 1740462813695
			- [:span]
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67bd5afe-115b-4ccf-8796-405a5ee5ae14
			  hl-type:: area
			  hl-stamp:: 1740462845373
	- Model selection
	  ls-type:: annotation
	  hl-page:: 11
	  hl-color:: red
	  id:: 67bd5b09-4ec7-4b75-936d-2404ae25370a
		- One of the most challenging tasks in the assessment of machine learning models is to ﬁnd the *BEST* model or best ﬁt hypothesis.
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: blue
		  id:: 67bd5b61-aafe-4081-8950-ca42202d466d
		  collapsed:: true
			- As we discussed earlier in our ‘trips around the city’ example, there are many ways of grouping and combining data and many ways to adjust the model’s controls (parameters and hyper-parameters). This will vary a model’s ﬁtness to the data.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67bd5b78-30bd-42b6-92c5-5a38351af252
			- There is *no easy way* to know if a certain model will offer the best ﬁt. There is so much data and so many possible features that we can’t be sure which model to choose. That’s why we have to try many different models.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67bd5b88-76d2-41e8-bcfc-0c48e84f21ef
		- Trying out models
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: red
		  id:: 67bd5ba7-1978-4679-a193-30062bb1b0a1
		  collapsed:: true
			- If you remember the clustering problem we discussed previously, we are not sure about the exact number of clusters, so we cannot know the best or most accurate or most useful model. The models we choose will have a direct effect on the quality of the output.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5bb6-5c87-4e36-ab5b-8ba33c950fe0
			- [:span]
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5bc9-45b3-450d-bd82-3aaee105ab1b
			  hl-type:: area
			  hl-stamp:: 1740463048091
			- There are many effective ways that people approach this problem:
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5bd4-05e9-4169-a7c5-dc643441bfa9
				- look at averaged evaluation scores on many random test datasets
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5bdb-2fb2-4946-8a81-c6b2d3fbb4fc
				- cross-validation, that is train using one dataset and test on another, try rotating them and test again, for example if you have datasets A, B and C try AIC, BIC etc.
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5be4-7d66-4694-984c-050a4fd0a4d7
		- Over-ﬁtting
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: red
		  id:: 67bd5ca7-6e36-4cff-bc06-61046d221a21
			- Sometimes when a model learns the details and noise within a training dataset the knowledge can negatively impact the performance of the model on a new dataset. In machine learning, we call this *Over-ﬁtting*. In other words, designing a model to suit the training dataset can result in poor performance on evaluation or new data.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5d86-4ea1-405d-a083-2fc34647ac28