file:: [SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf](../assets/SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf)
file-path:: ../assets/SIT307_SIT720 - Machine Learning - Week 1 - Introduction to machine learning.pdf

- 01-Introduction to machine learning
  hl-page:: 2
  ls-type:: annotation
  id:: 67bd2b54-31c4-43be-983d-83a0693219a1
  hl-color:: red
	- Deﬁning Machine Learning
	  ls-type:: annotation
	  hl-page:: 5
	  hl-color:: red
	  id:: 67bd2ccb-cb75-47ec-a96b-549c0275c6bb
	  collapsed:: true
		- The 1959 deﬁnition below makes Machine Learning (ML) seem like magic - “Field of study that gives computers the ability to learn without being explicitly programmed,” (Samuel 1959)
		  hl-stamp:: 1740451043374
		  hl-page:: 5
		  ls-type:: annotation
		  id:: 67bd2ce0-ce7a-4727-975b-867e67467178
		  hl-color:: green
		  collapsed:: true
			- As we explore further you will see ML is a set of tools to derive meaning from data. For now, here is another deﬁnition that describes ML in mathematical terms.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2cfd-26ad-4fe7-add0-6968a6b65f20
		- Machine Learning as an equation
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: red
		  id:: 67bd2d0b-2ec7-4b76-a5d1-29d2fb2c3b31
		  collapsed:: true
			- “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E,”(Mitchell 1997, p. 2)
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67bd2d18-d06f-41e6-ad65-3c98dec63137
			- This is an elaborated, perhaps overly complicated deﬁnition of how a computer program learns. It learns only when performance improves with experience. So, what is experience? It is the data that we provide for the machine to process.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d34-0398-47af-aeea-e0d50c681a64
			- Experience E, is the information the machine processes using the tasks T, to get closer to what you want to produce, the performance measure P. If the machine continues to perform the tasks but produces rubbish then it hasn’t learned.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d4a-825c-4f0c-8676-3af537459635
			- A machine can be said to learn if it can perform tasks on the information you supply, and react to the data to get results that get closer to a useful result over time.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d59-3982-4235-8c03-96b042b405b7
			- Consider how humans learn and make decisions. We analyse data, ﬁnd patterns and use those patterns to make decisions or to predict the outcome of future events. For example, if you buy a car, you might look up reviews, check the features of different models, think about how you want to use the car, take some test drives and then make a choice.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d6f-af49-4a29-b265-44f79d4bd57a
		- Too much data
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: red
		  id:: 67bd2d7b-61d5-4578-8694-82f00f6fd374
		  collapsed:: true
			- So why do we need ML? It is all about the volume of data available to us. There is so much information that we cannot make sense of it. It’s as though you have to choose the perfect vehicle for every person at Deakin. It would be a massive task to know what every person wants and needs and to add all the details of various models of vehicle in order to make good decisions.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2d94-76f2-4c6d-aac4-37f53b44a9a6
			- Automated systems (ML) will learn from the data we give them and, importantly, respond to changes in the data they are given to produce useful results.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: yellow
			  id:: 67bd2da4-9bdd-4701-b40d-3e0ab6ede637
	- Real-world applications of machine learning
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: red
	  id:: 67bd2dbc-6873-46ba-8e71-16c650778f9f
	  collapsed:: true
		- Machine learning involves the use of computer algorithms to learn how to perform different tasks.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67bd2e6f-b9e0-4414-9d21-3837012880ee
		- Let’s look at a few examples where machine learning is being applied.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67bd2e77-8be8-4ef6-a563-ae6a68ac7f43
		- Robotics
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2e7e-cda9-43e0-b3d7-8a4decf97919
		  collapsed:: true
			- Robots are going to be our companions in the future. They will do our cleaning, cooking and vacuuming. They’ll do our reading, schedule tasks, remind us to take our medications and play our favourite song at just the right time and volume. Machine learning is a fundamental part of enabling robots to perform these activities.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: yellow
			  id:: 67bd2e85-c252-4211-9755-c003db86729a
			- Simultaneous Localization and Mapping (SLAM) uses data to ﬁnd routes for rescue robots. Check out this amazing demonstration of real-time mapping using the pulsing light of LIDAR.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: green
			  id:: 67bd2e95-6785-4b25-a595-7633682dd7cf
		- Computer vision
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2ea1-02df-4224-be72-22fa00ef80d5
		- Board Games
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2eb0-3021-4144-9f48-cd6fee280a58
		  collapsed:: true
			- Board games are one of the oldest applications of machine learning. There are many successful algorithms which play checkers and board games such as ‘Go’.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f3c-fa1f-43d1-8431-983814830f96
				- In March 2016; AlphaGo, the board-game-playing AI from Google’s DeepMind beat Korean Go Champion Lee Sedol 4-1. AlphaGo uses deep neural networks and Monte Carlo tree search.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f44-07f7-49c4-b1a7-a34560abf976
				- Watch this 3 minute trailer for the AlphaGo documentary. The win is a deﬁning moment in AI similar to when the computer, Deep Blue, beat Garry Kasparov at chess in 1996.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f4c-9621-4a83-aabe-9e98f2c8ad48
		- Voice Recognition
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2f58-b571-4942-b9a0-a7d9737b4b0b
		  collapsed:: true
			- Speech recognition and machine learning have experienced waves of major innovations through recent history. It has beneﬁted from advances in deep learning, as well as big data and is widely used in a variety of applications.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f5d-7adf-48cc-bac2-517595b38d88
			  collapsed:: true
				- Technologies such as Siri and Google Home are examples of this. Siri uses speech recognizer, natural language processing and text-to-speech techniques.
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f65-3760-48bb-8427-0fc4e78cb708
			- The Australian Government Tax Ofﬁce now holds millions of voice prints to identify Australians.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f79-7b57-43fd-96fc-8ecab36d7e3a
			  collapsed:: true
				- Their voice is compared with a stored voiceprint which captures more than 140 unique physical and behavioural characteristics of a person such as length of the vocal tract and nasal passage, the size and shape of the larynx, pitch, cadence and accent. (Nott,2016)
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2f7f-bda8-4f84-9fda-ea32b56703de
			- How would you go at recognising people by voice? How about a million people? This is where machine learning excels.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2f8f-a15c-4069-b7b1-1636e5fba7a2
			  hl-stamp:: 1740451731673
		- Digit Recognition
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2fa6-7ee9-44c6-bf35-5cf0e7361f57
		  collapsed:: true
			- Digit Recognition is the task of reading in the images of handwritten numbers and letters and outputting its machine-encoded equivalent. Machine Learning methods (SVM and Deep Learning) have hit >99% accuracy for this task.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fb0-041c-4e26-8307-dda9c6bbe820
			- Other examples are detection of numberplates, printed numbers on bills, handwriting and CAPTCHA.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fba-3531-4bfe-b883-75356efb2db2
		- Other interesting applications
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: red
		  id:: 67bd2fcc-ce11-4bf7-8d65-612184a882c4
		  collapsed:: true
			- A wide variety of machine learning applications are related to:
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: blue
			  id:: 67bd2fd3-0562-468a-b5eb-3ed82402d7f1
				- healthcare analytics: diagnosis and prognosis
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd2fd8-0444-4140-933a-5b4f2d3e4682
				- stock market prediction
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3028-0e8e-4c82-b2b6-b744b4235d7f
				- business analytics
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3031-50ac-469a-9a9d-5cc895eca6f6
				- facial recognition
				  ls-type:: annotation
				  hl-page:: 6
				  hl-color:: yellow
				  id:: 67bd3039-3ba8-44c2-890f-c59fd1a171ac
	- Machine Learning steps
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: red
	  id:: 67bd3096-2ef5-4d39-afe7-6990447cb14a
	  collapsed:: true
		- Have you ever thought about how you learn to make decisions?
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67bd31b0-577f-4cb7-b98f-e9b36bf08914
		  collapsed:: true
			- Let’s assume that we have been asked to research a problem and make a decision. You must have access to information (data) from which you can learn. Once you have data, what do you do with it? Most people analyse the information to ﬁnd patterns and relationships. You make a decision based on your work. Finally, you evaluate the model. Did you make a good decision or could it have been better?
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67bd31bd-9ede-47c6-98c2-69aa798dc79a
			- Let’s look at each of these stages in more detail and relate them to ML.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67bd31ca-5877-43a0-a9ba-50a11fe2d61f
		- Step 1: Data Manipulation
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd31d2-ef84-445c-beea-5448e2389e56
		  collapsed:: true
			- This is a process of data preparation. ML usually uses the largest sets of data available.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd31e6-8d7f-41a2-83d5-6ebf61017014
			- **Data Acquisition** - The ﬁrst step in data manipulation, data acquisition is the process of sampling information that illustrates real world physical conditions with a predeﬁned measurement. Using our car example, you might measure engine size, number of doors, size of tyres etc.
			  hl-stamp:: 1740452384649
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd31f2-3ac7-4ff5-a1fe-f419e62c5f6a
			  hl-color:: green
			  collapsed:: true
				- The data acquired should be reliable for converting into digital numeric values that can be manipulated by a computer. Number of car doors is easy; style is less easy to deﬁne numerically.
				  ls-type:: annotation
				  hl-page:: 7
				  hl-color:: yellow
				  id:: 67bd3200-9935-4654-b08c-40b085453d1c
				  hl-stamp:: 1740452405405
			- **Data Cleaning** - Once the data is properly stored, any redundant, noisy, unusable parts of it should be trimmed. Data cleaning is a major step as real-world datasets are highly affected by noise, redundancy and missing values. We might delete any three-wheeled cars because they’re so unusual.
			  hl-stamp:: 1740452538876
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd320a-044d-4b0e-9c65-3779a83447b3
			  hl-color:: green
		- Step 2: Analytics
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd3212-76bd-4a2c-8133-7630598b321c
		  collapsed:: true
			- **Analytics** - The second main step in machine learning, analytics mainly involves ﬁnding relationships and correlations in the prepared data in order to design an accurate model based on that input data
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd321e-8864-4951-92ea-1fefb2c09dae
			  hl-color:: green
			- **Exploratory Data** - in addition, analysis is an approach for analysing datasets in order to summarise their main characteristics or features. Many exploratory data analysis methods use visual illustration of data, based on different features. Things like graphs, charts and tables make data easier to understand.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3266-7d7d-4677-be2f-491b98fec230
			  hl-color:: green
			- **Predictive Machine Learning** - the last stage of Analytics. It uses a variety of statistical techniques such as predictive modelling in order to build a classiﬁer or intelligent system for decision making. We will come back to these ideas over the next few weeks.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3295-4112-4fae-b4b6-2de597a404ba
			  hl-color:: green
		- Step 3: Evaluation and Visualisation
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: red
		  id:: 67bd34e3-69d7-4a68-b222-291c72648548
		  collapsed:: true
			- The ﬁnal result of Analytics is an intelligent system or model. As the last step of ML design, we have to evaluate the performance of the system. “Did I choose the right car?”
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd3514-c3b1-441b-9e90-b07111221e98
			- Reﬁnement - if the quality and performance of the intelligent system does not achieve a satisfactory outcome, the Reﬁnement procedure is required and another round of data manipulation and analytics becomes necessary. Again, we will come back to these ideas as you move through the Unit.
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67bd3529-b57b-4a7a-8b2d-1a6c90548dbe
			  hl-color:: green
			- In this Unit we mainly focus on the Analytics step. However it will be necessary to use parts of the Data Manipulation step to build a model.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: blue
			  id:: 67bd3553-11a6-4e61-b497-5ae3b3e2c3e3
		- [:span]
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67bd31a3-f4f0-41c2-b966-e7a7634efcae
		  hl-type:: area
		  hl-stamp:: 1740452258386
	- Supervised learning overview
	  ls-type:: annotation
	  hl-page:: 8
	  hl-color:: red
	  id:: 67bd3586-fb82-4b23-b1a1-7e6a1051c161
	  collapsed:: true
		- The majority of practical ML uses supervised learning. This brief overview will give you a broad understanding of supervised learning. It’s an important concept and we’ll be going into much more detail in the up coming weeks.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67bd35ce-242a-468e-be77-42507955e8c7
		- **Supervised learning** - can be deﬁned as: learning a function (otherwise known as a model) from data to relate inputs to known outputs.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67bd35e2-9758-4e69-896c-54e397a8a38d
		  hl-color:: green
		  collapsed:: true
			- If the concept is unfamiliar it may take several different descriptions or deﬁnitions to make sense of the idea.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67bd3604-0974-4c8c-98c2-6c0f11522943
		- Supervised learning is trained
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd3612-02b5-49f8-a886-046bffc56225
		  collapsed:: true
			- One deﬁning characteristic of supervised learning is that datasets have relationships built in from the start.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd361b-62db-4883-9ebe-e293555bb23b
			  collapsed:: true
				- For example, if you have datasets on vehicles you know that most cars have four wheels while most bicycles have two. You could say that having two wheels is a function of being a bicycle (with some exceptions) and having four wheels is a function of being a car (with the exception of very rare three-wheeled cars like this Fuldamobil S-7).
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd362b-1271-4e88-95ac-6630700aefef
				- This makes it possible to train the algorithm. The machine learns using known relationships in the data.
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd37ae-cd24-4f43-8bf6-16ffb780f812
		- Training and evaluation data
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd37c1-e865-41b4-885e-f89f63e6b397
		  collapsed:: true
			- For supervised learning, training requires dividing the available data into **training data** and **evaluation data**. Most of the data is used to develop and train a function ‘model’. We know the relationship between the inputs and the outputs. In other words, we know the ‘right’ answers so we can select, manipulate and reﬁne features to train the machine. The more often the answer is correct, (ie. “This is a bicycle”), the closer you are to having a useful algorithm
			  hl-page:: 8
			  ls-type:: annotation
			  id:: 67bd37d8-2c7c-4699-b52f-d5a0cd74e10a
			  hl-color:: green
			  hl-stamp:: 1740453871080
				- The evaluation data can be used to test the model with fresh, unused input data.
				  ls-type:: annotation
				  hl-page:: 8
				  hl-color:: yellow
				  id:: 67bd37fb-134a-403a-a1d5-7afb8e476222
		- A mathematical deﬁnition
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd3806-84a9-4c89-91c5-8a1e7b45f006
		  collapsed:: true
			- Machine algorithms must be described mathematically. Remember that computers understand numbers so we must translate our questions into formulas or algorithms so they can process answers.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd382a-ef4a-45bc-92ba-4aa27f5f24bc
			- In **supervised learning**, the training data includes output information (labels/targets).
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: green
			  id:: 67bd3831-27d8-463b-9464-3c269ea72780
				- **Target function**: $𝑓: 𝑋 → 𝑌$
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3849-d21e-4b52-9c13-0abce8e2addb
				  hl-color:: green
				- **Examples**: It is in the form of $(𝑥, 𝑦)$, denoted as $(𝑥1, 𝑦1)$, . . . , $(𝑥𝑛, 𝑦𝑛)$.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd385e-3efd-44da-ae3d-d9ea4cd1f7df
				  hl-color:: green
				- **Hypothesis** $𝑔: 𝑋 → 𝑌$ such that $𝑔(𝑥) = 𝑓(𝑥)$.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3887-9233-4e15-aec8-18bca1b8ab0c
				  hl-color:: green
				- $x =$ set of attribute values (attribute-value representation)
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd38c9-bcf0-4806-82f2-d0a70536d01e
				  hl-color:: green
				- $y =$ a discrete label (*classiﬁcation*), a real valued number (*regression*).
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd38dd-bd3e-4ecc-b9cc-8235e3d8f725
				  hl-color:: green
		- Two types of supervised learning
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: red
		  id:: 67bd38f8-af4e-4fc5-b8c5-ea4a397a1bec
		  collapsed:: true
			- 1.0 Classiﬁcation problems
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: blue
			  id:: 67bd39ae-68a5-4539-9568-46fcbc09ff89
				- **Decision boundaries** - in a supervised learning problem with two classes, decision boundaries are a hyper-surface that partitions data space into two sets, each of these sets represent one of the classes. In other words, you divide the data according to a trained algorithm.
				  hl-stamp:: 1740454342948
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd39ba-cedf-49d5-983c-a5f22c671470
				  hl-color:: green
				  collapsed:: true
					- Consider the following ﬁgure as an illustration of supervised learning.
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3a9f-9ff9-4567-9714-60a91f9d722e
					- As you can see on the left, in some less complex cases a linear decision boundary can solve the classiﬁcation problem. However as illustrated on the right, more complex cases, require complicated decision boundaries.
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3ae6-3c70-4527-b3cb-2a7fd9dcda64
					  hl-stamp:: 1740454637951
					- [:span]
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3ad3-9789-452c-8b8d-2c9156ae234f
					  hl-type:: area
					  hl-stamp:: 1740454609761
					- {{video https://youtu.be/nKW8Ndu7Mjw}}
			- 2.0 Regression problems
			  hl-page:: 8
			  ls-type:: annotation
			  id:: 67bd3f20-7a2b-4672-b343-d30e438c6c9c
			  hl-color:: blue
			  hl-stamp:: 1740455762211
				- **Regression** - Another example of supervised learning, is regression. The overall idea of regression is to examine the relationship between response variables and one or more predictor variables. This examination can result in a hyperplane, representing the regression analysis. The following ﬁgure, illustrates a regression problem in 2 dimensions.
				  hl-page:: 8
				  ls-type:: annotation
				  id:: 67bd3eff-f4cf-45f6-a155-6d6279de6051
				  hl-color:: green
				  collapsed:: true
					- [:span]
					  ls-type:: annotation
					  hl-page:: 8
					  hl-color:: yellow
					  id:: 67bd3f68-b036-4d45-993c-3e02413bce6a
					  hl-type:: area
					  hl-stamp:: 1740455779706
	- Unsupervised learning overview
	  ls-type:: annotation
	  hl-page:: 9
	  hl-color:: red
	  id:: 67bd40c0-9595-405c-b61d-e15b7d119680
	  collapsed:: true
		- This brief introduction will give you an overview of the material we will cover in weeks 3 and 4.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd40fe-c010-4416-a7dc-504504de7421
		- The main question in unsupervised learning is *How do you ﬁnd the underlying structure of a dataset which is unlabelled?* How does an algorithm learn patterns from (unlabelled) data ($𝑥_{1}, . . . , 𝑥_{𝑛}).
		  hl-page:: 9
		  ls-type:: annotation
		  id:: 67bd422d-3bc9-4f1d-9fc4-e73d48d5b366
		  hl-color:: blue
		- In other words, can a machine algorithm learn from very large sets of data without additional information about the data? Can it ﬁnd patterns and relationships, make sense of data and make decisions or predictions?
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd4266-e232-4202-b020-d858981b4b21
		  collapsed:: true
			- For example, if you had lots of data on all the ways people move around a city: long trips, short trips, time of day, vehicle type, direction of travel etc in a mixed up dataset without labels, would machine learning be able to make sense of it and tell you when to leave home to get to work on time?
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd435a-5930-450f-bf46-6673d8b30d04
		- Popular approaches in unsupervised learning are:
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67bd4369-881d-4bf6-ac72-464b6fb23d37
		  hl-stamp:: 1740456815568
		  collapsed:: true
			- clustering (similarity-based), density estimation
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd4379-db90-47da-98c2-e849411007c3
			- factor analysis
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67bd4380-2e8a-4bad-9da4-e9f5ec89bac9
		- Clustering
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: red
		  id:: 67bd4394-9313-432d-987c-5d566c46749f
		  collapsed:: true
			- **Clustering** - is the process of grouping similar points together. The goal of this unsupervised machine learning technique is to ﬁnd relative similarities in the data points. But why do we need to perform this task? Because it will give us insight into underlying patterns or different groups within the dataset(s).
			  hl-page:: 9
			  ls-type:: annotation
			  id:: 67bd439c-76e5-46aa-8672-21d625d8e0eb
			  hl-color:: green
			  collapsed:: true
				- Let’s consider an example. The unlabelled data points (before clustering) are shown at the top of the following ﬁgure.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd43e1-610f-4a0f-99c3-a2d88133db9d
				  collapsed:: true
					- By performing clustering based on the similarities and correlations, we might ﬁnd 2 clusters in these data points. For example, we might determine trips around the city of less than 25 km and more than 25 km. This creates two groups. The art is in working out if 25 km is a good cut-off point. Is it useful? Perhaps it would be more useful to extract more clusters.
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd4444-933a-4178-8bb3-d5ab20b5647d
					- We can perform the clustering in a way that results in more than two clusters. Let’s say 3 or even 4 clusters. We might have a cluster of trips that are more than 1 km and less than 10 km. Then perhaps the machine might overlay that with a cluster of pedestrian data. Would that be useful? How could you make it better?
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd4458-4d89-46ef-8fc0-483177ffecf6
					- [:span]
					  ls-type:: annotation
					  hl-page:: 9
					  hl-color:: yellow
					  id:: 67bd43f4-847b-4c0e-a243-92ad12b52e58
					  hl-type:: area
					  hl-stamp:: 1740456947520
			- Since the data is **unlabelled** in clustering problems, based on the features and the **expectation of the user** from the behaviour of the data, we can look for any number of clusters.
			  hl-page:: 9
			  ls-type:: annotation
			  id:: 67bd4490-4c0d-46c1-9aef-afb06975b689
			  hl-color:: green
			  collapsed:: true
				- Say my expectation is that most trips in the city are less than 10 km. If the algorithm presents me with a cluster that contains trips of less than 15 metres, is that useful? It depends on what I’m trying to ﬁnd out. Perhaps I would change that parameter.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd44ac-1fcd-4f6a-9bf8-7ec67b620018
		- A real-world example
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: red
		  id:: 67bd44c9-efa8-497d-942a-f1d23fc111fe
		  collapsed:: true
			- The popular entertainment company Netﬂix opened a competition for the best collaborative ﬁltering algorithm to predict user ratings for ﬁlms. They provided a training data set of 100, 480, 507 movie ratings that 480, 189 users gave to 17, 770 movies.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: blue
			  id:: 67bd4503-47df-4a50-8995-57f39458b121
			  collapsed:: true
				- This competition was a real “Movie Recommendation Problem”. They were expecting contestants to predict movie ratings for users. The winning Bellkor solution won the small team 1 million dollars from Netﬂix. In such problems there are no labels available for data points. That is why we are categorizing such problems as unsupervised learning.
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd451a-62f8-40fd-9c17-5c57ad06c82f
				- [:span]
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd452b-c899-4cd0-a387-9807979a7152
				  hl-type:: area
				  hl-stamp:: 1740457257296
			- Generally, the potential tasks for ML unsupervised learning are:
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: blue
			  id:: 67bd4536-3c00-459b-849a-cc61e098207b
				- information retrieval
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4543-2744-40dd-8697-9a52f598e0e4
				- data compression (reduction)
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd454b-266f-4e95-9ca8-f40a3247be94
				- anomaly detection
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4553-577e-4f59-9563-0fb976875b25
				- data understanding and visualization
				  ls-type:: annotation
				  hl-page:: 9
				  hl-color:: yellow
				  id:: 67bd4559-f9ab-4a0e-a28d-63049b0808db
	- Reinforcement learning
	  ls-type:: annotation
	  hl-page:: 10
	  hl-color:: red
	  id:: 67bd5961-8c54-4163-a381-7a597df09084
	  collapsed:: true
		- Reinforcement learning is another important type of machine learning algorithm.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67bd596c-aabc-4e4f-af96-1e81f4732cbc
		- **Interactions** - in this algorithm, an agent learns how to behave in an environment by performing actions and learning from interactions. Learning from“interaction with the environment” replicates the way humans learn by instinct, curiosity and experimentation.
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67bd597a-026b-42d9-8073-d303501fe297
		  hl-color:: green
		  collapsed:: true
			- The learner (a machine or a human) acts on its environment, receives some evaluation based on its action (reward), but is not told which action is the correct one for a desired end goal. The learner’s actions affect the data it receives later.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67bd599c-b26c-425c-a0ee-fef2c2a46bc5
		- There are many logic games like Chess, with a sequence of decisions. It is possible to train an agent to learn how to play Chess by reinforcement learning; if the actions and the corresponding rewards are well deﬁned. For example, if I move my Queen out to a vulnerable square, it gets taken off the board. I lose. Next time I’ll try something different.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: yellow
		  id:: 67bd59b6-b735-43d4-9266-71a913f773ba
		- [:span]
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: yellow
		  id:: 67bd5a0f-5e8a-493e-9891-853dcef4acbb
		  hl-type:: area
		  hl-stamp:: 1740462605446
	- Model evaluation and selection``
	  hl-page:: 11
	  ls-type:: annotation
	  id:: 67bd5a29-e7ae-4a59-bea6-223279755caf
	  hl-color:: red
	  collapsed:: true
		- Model evaluation
		  hl-page:: 11
		  ls-type:: annotation
		  id:: 67bd5a53-3e15-4310-8fec-d5e2d37f6e1c
		  hl-color:: red
		  collapsed:: true
			- In machine learning problems, we should always evaluate a model to determine if it will do an excellent job of predicting the labels on new and future test data.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5a6c-2c78-4201-8855-9b274a470643
			- Because future instances have unknown label values, we need to check the accuracy of a machine learning model on test data with correct labels that we already know. We use this assessment as a proxy for predictive accuracy on future data (which is unknown to us!). For this purpose we need to:
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5a7b-fb04-45ae-9e80-2402b910b690
				- randomly split examples into a **training dataset** and **test dataset**
				  hl-page:: 11
				  ls-type:: annotation
				  id:: 67bd5a89-e82a-4278-9fed-c85881186985
				  hl-color:: green
				- use the training dataset to **learn a model**
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: green
				  id:: 67bd5aa4-0ba3-49ce-844a-ccc7125df62a
				- **evaluate the model** using the test dataset and a measurement (such as the accuracy of prediction)
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: green
				  id:: 67bd5ab4-4567-4d87-8753-1357858fed70
				- repeat for different random splits and then **average the results**
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: green
				  id:: 67bd5ac6-759a-4887-ad18-6821993eeff7
				- check the accuracy of results and try again (iterate) until the model makes useful predictions
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5ad5-3e3b-413c-9f0c-66e83bfd3626
				  hl-stamp:: 1740462813695
				- [:span]
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5afe-115b-4ccf-8796-405a5ee5ae14
				  hl-type:: area
				  hl-stamp:: 1740462845373
		- Model selection
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: red
		  id:: 67bd5b09-4ec7-4b75-936d-2404ae25370a
		  collapsed:: true
			- One of the most challenging tasks in the assessment of machine learning models is to ﬁnd the *BEST* model or best ﬁt hypothesis.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: blue
			  id:: 67bd5b61-aafe-4081-8950-ca42202d466d
			  collapsed:: true
				- As we discussed earlier in our ‘trips around the city’ example, there are many ways of grouping and combining data and many ways to adjust the model’s controls (parameters and hyper-parameters). This will vary a model’s ﬁtness to the data.
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5b78-30bd-42b6-92c5-5a38351af252
				- There is *no easy way* to know if a certain model will offer the best ﬁt. There is so much data and so many possible features that we can’t be sure which model to choose. That’s why we have to try many different models.
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: yellow
				  id:: 67bd5b88-76d2-41e8-bcfc-0c48e84f21ef
			- Trying out models
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: red
			  id:: 67bd5ba7-1978-4679-a193-30062bb1b0a1
			  collapsed:: true
				- If you remember the clustering problem we discussed previously, we are not sure about the exact number of clusters, so we cannot know the best or most accurate or most useful model. The models we choose will have a direct effect on the quality of the output.
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: blue
				  id:: 67bd5bb6-5c87-4e36-ab5b-8ba33c950fe0
				- [:span]
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: blue
				  id:: 67bd5bc9-45b3-450d-bd82-3aaee105ab1b
				  hl-type:: area
				  hl-stamp:: 1740463048091
				- There are many effective ways that people approach this problem:
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: blue
				  id:: 67bd5bd4-05e9-4169-a7c5-dc643441bfa9
					- look at averaged evaluation scores on many random test datasets
					  ls-type:: annotation
					  hl-page:: 11
					  hl-color:: yellow
					  id:: 67bd5bdb-2fb2-4946-8a81-c6b2d3fbb4fc
					- cross-validation, that is train using one dataset and test on another, try rotating them and test again, for example if you have datasets A, B and C try AIC, BIC etc.
					  ls-type:: annotation
					  hl-page:: 11
					  hl-color:: yellow
					  id:: 67bd5be4-7d66-4694-984c-050a4fd0a4d7
			- Over-ﬁtting
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: red
			  id:: 67bd5ca7-6e36-4cff-bc06-61046d221a21
				- Sometimes when a model learns the details and noise within a training dataset the knowledge can negatively impact the performance of the model on a new dataset. In machine learning, we call this *Over-ﬁtting*. In other words, designing a model to suit the training dataset can result in poor performance on evaluation or new data.
				  ls-type:: annotation
				  hl-page:: 11
				  hl-color:: blue
				  id:: 67bd5d86-4ea1-405d-a083-2fc34647ac28
	- Mathematics and ML
	  hl-page:: 12
	  ls-type:: annotation
	  id:: 67bd5db6-c202-4968-bf81-dcae9dc17835
	  hl-color:: red
	  collapsed:: true
		- ML is based on maths. Maths underlies every decision, itera!on and output. To get great results, you need to understand the various mathematical concepts and processes that are the founda!on of your results.
		  ls-type:: annotation
		  hl-page:: 12
		  hl-color:: blue
		  id:: 67bd5dcb-9b57-44fd-bf55-acf0eb625b15
		  collapsed:: true
			- An expert Data Engineer will understand and apply these concepts. They will have knowledge and understanding of a range of models, the ability to select models, the parameters (or edges) to apply and understand why some models give be"er results than others.
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67bd5ddb-2e5d-448b-a66d-51c54eff3095
		- Some of the key areas you will explore this week are listed below:
		  ls-type:: annotation
		  hl-page:: 12
		  hl-color:: yellow
		  id:: 67bd5e1b-a910-45c7-883e-041e5bdd9c14
			- Vectors and basic vector opera!ons
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67bd5e3c-2f7c-40ee-b7fb-12d523e897d2
			- Matrices and matrix opera!ons
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67bd5e44-ac1c-4620-a256-f6beb7ecfae0
			- Basic concept of probability
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67bd5e4e-272d-4d59-b05f-8bcf31e1a9f3
			- Python programming: using diﬀerent modules and packages.
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67bd5e57-e00c-41b6-ba05-7154f58915d2
	- Vectors and its operation
	  hl-page:: 13
	  ls-type:: annotation
	  id:: 67bd5eb6-abb8-40bc-91df-5f5eb0c60337
	  hl-color:: red
	  collapsed:: true
		- Vectors
		  ls-type:: annotation
		  hl-page:: 13
		  hl-color:: red
		  id:: 67bd5ec9-3670-427c-80cd-ca215664b5bc
		  collapsed:: true
			- It’s outside the scope of this Unit to teach you maths skills but we will quickly do some revision of some mathematical concepts
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: blue
			  id:: 67bd5edc-c018-4166-adc6-180167a19d19
			- Vectors are a fundamental element of linear algebra and mathematics. They are also widely-used in machine learning algorithms.
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: blue
			  id:: 67bd5ee3-9552-4a18-9d32-353a86358013
			- Why know the maths
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd5ee8-a33a-44a7-9174-7a1e64f5237f
			  collapsed:: true
				- Understanding the mathematics allows you to select the best models for a task. It will support your decisions and provide the expertise to perform useful adjustments. Knowing how the maths operates within the models gives specialists the skill to manipulate data and extract the best information.
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd5f48-1c23-4f2c-8bf8-2b58ddf5959e
				- You can develop machine learning without in-depth knowledge of vectors, matrices and probability but it will be harder to get the best outcomes. Even though the various pre-programmed modules conceal some of the maths (we’ll start using modules later this week) if you understand how they work, you will have more control of your results.
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6293-d4bc-452b-8aee-e264fdc67413
				- Remember, there is no exam in this Unit. You are not expected to perform mathematical tasks under pressure.
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd62a7-5d61-44ed-8782-694f3fb97023
			- Feature vectors
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd62b4-c29c-4ec0-9048-f42ceb41c61f
			  collapsed:: true
				- **Feature vector** - why are we using vectors? In this unit, you will notice that most of the time a data instance is represented by a vector, more precisely, by a feature vector.
				  hl-stamp:: 1740464830357
				  hl-page:: 13
				  ls-type:: annotation
				  id:: 67bd62b9-97d1-4115-b9e6-289d34100ae1
				  hl-color:: green
					- Text documents, images, audio ﬁles, etc. are examples of data objects. Computation on these data objects can be performed using their vector representation.
					  ls-type:: annotation
					  hl-page:: 13
					  hl-color:: yellow
					  id:: 67bd62e2-1d94-465a-b0dd-2c428702b555
			- What is a vector?
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd62ed-a52d-4bce-a563-484671ae61b6
			  collapsed:: true
				- Visually, a vector quantity has both magnitude and direction but it is really a series of related numbers. Their role in ML is about relationships between data objects. The following is an illustration of a sample vector. Note the relationship between the visual representation and the matrix representation of the relationship between inputs and outputs.
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6314-8e0f-4615-8bac-1288d66fe826
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6322-d251-4fe8-89f0-6ac84714e2fe
				  hl-type:: area
				  hl-stamp:: 1740464927466
		- Vector operations
		  ls-type:: annotation
		  hl-page:: 13
		  hl-color:: red
		  id:: 67bd6351-d907-46a7-9604-4b69206ac457
		  collapsed:: true
			- There are three main operations in vectors. As we’ve seen vectors can be represented as a one column matrix
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: blue
			  id:: 67bd637d-76a1-40ff-a7ab-14ce4e4f19c9
			  collapsed:: true
				- ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6388-3d1e-4882-ae75-b3d13cadb7e3
				  1. Transpose
				- ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd638c-0972-4c1d-bd32-bc08346dd277
				  2. Add
				- ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6393-8011-4844-ba49-7fc8617207d7
				  3. Inner product
			- Let’s start by taking two simple matrices 𝑥 and 𝑦:
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: blue
			  id:: 67bd63a6-0083-41f8-aec4-71fbe918eed0
			  collapsed:: true
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd63b2-6a48-413e-8ed1-9793a34bf171
				  hl-type:: area
				  hl-stamp:: 1740465072993
			- How are these three operations implemented?
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: blue
			  id:: 67bd63c4-e2e7-40cb-9887-060aa0db5cf5
			- Transpose
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd63d5-69fc-4e58-acc8-862cfb29ee96
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd63dd-2217-4ddb-ac34-18c915d8d247
				  hl-type:: area
				  hl-stamp:: 1740465116492
			- Add
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd6422-ea1a-41fc-b3e0-4105112aa936
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6438-5533-4cac-8ff1-44ed87c3af6e
				  hl-type:: area
				  hl-stamp:: 1740465207113
			- Inner product
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd6443-f401-49bb-9417-a8e38ae9aca6
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd644a-9d5c-4bb1-a9d9-1a5e054d1a12
				  hl-type:: area
				  hl-stamp:: 1740465225555
			- Magnitude of a vector
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: red
			  id:: 67bd6454-39f2-4c32-9601-ac537d813f74
				- How do we compute the magnitude of a vector or its length geometrically?
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd645d-61c8-4703-9ba2-cfe11484d273
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6467-3096-4ebd-8545-b2ee8b258987
				  hl-type:: area
				  hl-stamp:: 1740465254464
				- The above length is also called 2-norm of a vector.
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6478-52df-4853-afc7-8bd4bc00c6f2
				- [:span]
				  ls-type:: annotation
				  hl-page:: 13
				  hl-color:: blue
				  id:: 67bd6482-083b-4f12-802b-fe1364c7c6b1
				  hl-type:: area
				  hl-stamp:: 1740465280894
	- Distances between vectors
	  ls-type:: annotation
	  hl-page:: 14
	  hl-color:: red
	  id:: 67bd650e-5e7b-4b52-84b8-a699b83e801a
	  collapsed:: true
		- **Cosine similarity** - is a similarity function often useful in information retrieval. It measures the cosine of the angle between two vectors. So Cosine similarity is deﬁned to be a measure of similarity between two vectors of an inner product space.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67bd653c-7aa2-4071-9570-6bc871bb4438
		  hl-color:: green
		- On the other hand, **cosine distance** measures the angular difference between 2 vectors. In other words, the cosine distance seeks to express vector **dissimilarity** in positive space and hence it does this by subtracting the similarity from 1
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67bd6555-8ffc-40ea-9aab-edd2037baeb1
		  hl-color:: green
		- [:span]
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: yellow
		  id:: 67bd6585-8233-48e9-bd04-bde6cc92b578
		  hl-type:: area
		  hl-stamp:: 1740465540119
		- The cosine distance above is deﬁned for positive values only. Cosine distance can be computed via Euclidean distance if vectors are made unit vectors.
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: yellow
		  id:: 67bd6592-15de-4fd3-bef7-250d60fb507a
	- Matrix algebra
	  ls-type:: annotation
	  hl-page:: 15
	  hl-color:: red
	  id:: 67bd666f-5180-4bf0-875e-ff2bbea8b1b5
	  collapsed:: true
		- Matrices are also a fundamental element of linear algebra and extremely useful in machine learning. Most of the machine learning methods deal with matrix operations. The main two features of any matrix is the number of rows and the number of columns.
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67bd6685-8ca2-4036-8b97-a83d5a028920
		  collapsed:: true
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6693-0a1b-40a3-8d8e-12293f2750ed
			  hl-type:: area
			  hl-stamp:: 1740465810186
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd66ab-14ad-41b4-ab53-ec3e331b8deb
			  hl-type:: area
			  hl-stamp:: 1740465833887
		- Basic operations
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd66c0-603b-4b08-a04d-a6532ad9437f
		  collapsed:: true
			- Next we review some basic operations in matrices.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd66ea-53eb-4ea8-9d45-040de9e9f6db
		- Matrix Addition/Subtraction
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6700-7f2b-4075-a55c-3f99fb2a5144
		  collapsed:: true
			- You can add or subtract matrices if they are the same size.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6712-c532-4d12-bbab-8594bf411a06
			- The elements in the corresponding positions are added or subtracted. Subtraction is similarly done:
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6728-47b3-45ca-b014-59c62a704f29
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6733-0129-4703-a4f2-69c7d4999c93
				  hl-type:: area
				  hl-stamp:: 1740465969900
		- Scalar Multiplication/Division
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd675a-2203-42cf-b186-c89f43cf368f
		  collapsed:: true
			- To multiply a matrix 𝐴 with scalar 𝑎, multiply each element of 𝐴 and 𝑎 as below:
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6767-70db-4aee-8931-ae71d30453e5
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd678c-3faa-4e9b-b912-e7b285cd8d31
				  hl-type:: area
				  hl-stamp:: 1740466055013
			- Division is similarly done except that division by 0 is not allowed for obvious reasons.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd67aa-a5e5-413a-a6f8-a738acfa6e70
			  hl-stamp:: 1740466106909
		- Elementwise Matrix Multiplication
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd67c5-2d96-4e47-b74a-6138cd64209c
		  hl-stamp:: 1740466182709
		  collapsed:: true
			- You can multiply any two matrices element-wise if they have the same size. Consider $𝐴⨀ 𝐵 = 𝐶$. Now $𝐶(𝑖, 𝑗)$ is computed as product of $𝐴(𝑖, 𝑗)$ and $𝐵(𝑖, 𝑗)$.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd67cf-6d77-4749-a890-f7896b376a2a
			  hl-color:: blue
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd67fa-7852-47cd-9560-6723fe4a27ed
			  hl-type:: area
			  hl-stamp:: 1740466169232
		- Matrix to Matrix Multiplication
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd683a-5b67-4551-bc47-6eaa6524fcd2
		  collapsed:: true
			- You can multiply any two matrices if the number of columns in the ﬁrst matrix is **equal** to the number of rows in the second matrix. Consider $𝐴𝐵 = 𝐶$. Now $𝐶(𝑖, 𝑗)$ is computed by dot product of $𝐴(𝑖, : )$ and $𝐵(: , 𝑗)$.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6845-38c9-4878-b4a7-d12c49ac1005
			  hl-color:: blue
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6881-adb4-4387-b0e1-f9b33d665c47
			  hl-type:: area
			  hl-stamp:: 1740466304478
			- Note: Matrix multiplication is NOT commutative. In other words, multiplication order matters. In general $𝐴𝐵 ≠ 𝐵𝐴$. In some case they may not even be size compatible if multiplied in the other order.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6894-8599-4b15-9ec6-1b8943ec002f
			  hl-color:: blue
		- Rectangular and Square Matrices
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd68b4-fa0f-46a8-8519-f6cfbb96ceb5
		  collapsed:: true
			- If a matrix 𝐴 has size 𝑚 × 𝑛 such that 𝑚 = 𝑛, then it is called a square matrix; otherwise it is a rectangular matrix.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd68c5-b74e-4a8a-9b56-0916c67c302f
				- is a square matrix and is a rectangular matrix
				  hl-page:: 15
				  ls-type:: annotation
				  id:: 67bd68f2-edf4-4be9-97b6-d84ff5d6d639
				  hl-color:: blue
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6902-9767-4627-afae-ee884a5c4ef0
				  hl-type:: area
				  hl-stamp:: 1740466432948
		- Transpose of a Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6915-a081-49cf-bf71-ef9788986f65
		  collapsed:: true
			- The transpose of a matrix 𝐴 is obtained by putting all the matrix elements on rows on its columns. Lets say 𝐵 is transpose of 𝐴 then,𝐵(𝑖, 𝑗) = 𝐴(𝑗, 𝑖).
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd691c-a67a-48c9-954c-4b301b1052d6
				- As an example, is the transpose of
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6992-1180-4034-866e-5ae7b05eacf9
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd69d7-a785-4ff7-83e2-01c428d12765
				  hl-type:: area
				  hl-stamp:: 1740466645637
		- Symmetric Matrices
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd69f6-bc0c-449a-8ad1-07a94c9b760e
		  collapsed:: true
			- A matrix $A$ is called symmetric if it is equal to its transpose, that is $𝐴 = 𝐴^{𝑇}$. Symmetric matrices are always square matrices.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6a00-a7e3-4c94-a7f7-16560933cc87
			  hl-color:: blue
				- is a symmetric matrix of size 2 × 2.
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6a29-117e-4ca9-8839-7a5fb97f65ca
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6a35-db75-4272-bddd-2ac099602fa7
				  hl-type:: area
				  hl-stamp:: 1740466739891
		- Diagonal Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6a4a-91f5-47f1-a912-0505b53fe662
		  collapsed:: true
			- A matrix $𝐴$ is called a diagonal matrix if $𝐴(𝑖, 𝑗) = 0$ for all $𝑖 ≠ 𝑗$. Diagonal matrix is always a square matrix. The following is an example:
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6a7d-7ab1-4aef-9c2d-2f7610952ae8
			  hl-color:: blue
				- is a diagonal matrix
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6ab1-7611-4c8d-95f5-5659e0e2c8a0
				- [:span]
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6acb-ad59-4dc7-9395-5c195a4057c1
				  hl-type:: area
				  hl-stamp:: 1740466890362
		- Identity Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6adf-82c2-4944-9656-c0c8d81be1f8
		  collapsed:: true
			- A matrix $𝐼$ is called an identity matrix if it is a diagonal matrix and $𝐼(𝑖, 𝑖) = 1$. The following is an example:
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6ae8-f6a3-4645-81ae-4d39667712e2
			  hl-color:: blue
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6b06-d45b-4f83-b222-5e67eacb5606
			  hl-type:: area
			  hl-stamp:: 1740466948606
			- Note that we often use $𝐼_{𝑛 × 𝑛}$ to denote an identity matrix of size $𝑛 × 𝑛$.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6b10-4d8d-4797-b57e-e448292d8ac3
			  hl-color:: blue
		- Inverse of a Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6b2e-5e6d-420d-b6d3-81c0307df96e
		  hl-stamp:: 1740467004331
		  collapsed:: true
			- A matrix $A$ is called as inverse of matrix $B$, if and only if $𝐵𝐴 = 𝐴𝐵 = 𝐼$. Since $𝐴𝐵 = 𝐵𝐴$ both $𝐴$ and $𝐵$ need to be a square matrix.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6b46-6e6b-4198-ab84-c67acfdc52b3
			  hl-color:: blue
			- If $A$ is inverse of $B$, we denote it as $𝐴 = 𝐵−1$
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6b6c-4c94-4132-95fd-d23d6651e06a
			  hl-color:: blue
			- Note: Inverse of a matrix $𝐴$ *exists* only if its determinant is nonzero.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6b89-152b-47a2-abfb-b9c41e02356c
			  hl-color:: blue
		- Orthogonal Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6ba2-61e5-46a3-9f35-2765f9d63bfb
		  collapsed:: true
			- A square matrix $𝑈$ is called an *orthogonal matrix* if its transpose is equal to its inverse, $𝑈^{𝑇} = 𝑈^{−1}$.
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6baf-b547-443b-a351-833e447df752
			  hl-color:: blue
			- Based on the deﬁnition, any identity matrix is orthogonal. The other examples of orthogonal matrices are *rotation matrices*. The following is an example of an orthogonal matrix:
			  hl-page:: 15
			  ls-type:: annotation
			  id:: 67bd6bdc-5961-421d-be3f-1772339e3e76
			  hl-color:: blue
			- [:span]
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6bfa-ecdd-41f5-a932-86007f33aed5
			  hl-type:: area
			  hl-stamp:: 1740467193047
		- Other Concepts related to a Matrix
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: red
		  id:: 67bd6c0f-ec37-4bd0-9853-4e1987e90825
		  collapsed:: true
			- There are many concepts regarding matrices such as:
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: blue
			  id:: 67bd6c28-2119-405e-9424-cbb388913392
				- Determinant of a matrix
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6c2d-6981-4cbf-bd3d-831e7072f54c
				- Trace of a matrix
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6c35-2f81-48e4-81f9-0556d12affad
				- Linear Independence
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6c3c-9be7-4f26-ab4b-9b5e37fb9221
				- Rank of a matrix
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6c43-007b-4a5c-afc4-8cd71b493551
				- Eigen values/Eigen vectors of a matrix
				  ls-type:: annotation
				  hl-page:: 15
				  hl-color:: blue
				  id:: 67bd6c4b-6f4c-4f6a-b4a5-097497fc0296
	- Some special matrices
	  ls-type:: annotation
	  hl-page:: 16
	  hl-color:: red
	  id:: 67bd6cce-aadd-4de7-bd53-aa21765a9624
	  collapsed:: true
		- **Vector space model** - the representation of a set of documents as vectors.
		  hl-page:: 16
		  ls-type:: annotation
		  id:: 67bd6cd9-a947-4488-997e-4e58f047ca42
		  hl-color:: green
		- It is a fundamental step in information retrieval operations. These operations can vary from a simple query problem to real search engines.
		  ls-type:: annotation
		  hl-page:: 16
		  hl-color:: blue
		  id:: 67bd6d09-72d5-40ea-bdc1-85f8ea287afb
		- In the *text data representation* step we had two documents with their corresponding feature vectors.
		  ls-type:: annotation
		  hl-page:: 16
		  hl-color:: blue
		  id:: 67bd6d16-bb54-46cc-b39f-c2bdebb1b2a9
		- By calculating the euclidean distance, we can easily ﬁnd the distance between these two documents. It can be utilised as a quick way to ﬁnd the closeness of two documents
		  ls-type:: annotation
		  hl-page:: 16
		  hl-color:: blue
		  id:: 67bd6d30-e224-4db0-832a-c0f1bc4ecaa9
		- [:span]
		  ls-type:: annotation
		  hl-page:: 16
		  hl-color:: blue
		  id:: 67bd6d3d-a662-4dc1-9492-88476ecac655
		  hl-type:: area
		  hl-stamp:: 1740467516491
	- Let's get started
	  ls-type:: annotation
	  hl-page:: 17
	  hl-color:: red
	  id:: 67bd6d7e-168d-45fb-9305-aea086fe8bd6
	  collapsed:: true
		- Beginners
		  ls-type:: annotation
		  hl-page:: 17
		  hl-color:: red
		  id:: 67bd6d91-f980-4bf4-a7a8-e5d691272013
		  collapsed:: true
			- If you’ve never programmed before, Python is a good way to begin.
			  ls-type:: annotation
			  hl-page:: 17
			  hl-color:: blue
			  id:: 67bd6d9a-ffa5-48c4-9eb5-02d058bda118
		- Experienced Coders
		  ls-type:: annotation
		  hl-page:: 17
		  hl-color:: red
		  id:: 67bd6dba-ba06-45ce-a7b8-c2da085df1f5
	- 1.17 Setting up Python
	  hl-page:: 18
	  ls-type:: annotation
	  id:: 67bd6df9-7e13-48e0-a2f4-32708e7e9be1
	  hl-color:: red
	  collapsed:: true
		- Jupyter Notebook
		  ls-type:: annotation
		  hl-page:: 18
		  hl-color:: red
		  id:: 67bea87a-bdbc-43ac-abc1-f782970f4fed
		  collapsed:: true
			- To start coding, open Anaconda and then open or launch Jupyter Notebook.
			  ls-type:: annotation
			  hl-page:: 18
			  hl-color:: blue
			  id:: 67bea88a-b4d2-433d-accb-c67c225676fa
			  hl-stamp:: 1740548237234
			  collapsed:: true
				- This will open a kernel and a shell to work in. The kernel does the hard work but you can use the shell to write and run your Python programs.
				  ls-type:: annotation
				  hl-page:: 18
				  hl-color:: yellow
				  id:: 67bea8ba-9745-4803-9a44-9353c8285e2d
			- This Jupyter Notebook video has a repeat of the Anaconda install instructions but the link will take you to the instructions on using a command line to open the Jupyter Notebook and offers a run-through of the environment.
			  ls-type:: annotation
			  hl-page:: 18
			  hl-color:: blue
			  id:: 67bea8ca-71e6-47cd-96c3-29849048476a
- 1.18 Types of variables
  hl-page:: 19
  ls-type:: annotation
  id:: 67bea8eb-49c6-4579-923e-8184270ea675
  hl-color:: red
	- You installed Python Anaconda in the previous step. It’s time to start some coding.
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: blue
	  id:: 67beac98-a3db-479e-936c-c7dfe87dfa54
	  collapsed:: true
		- Once again, if you are experienced you might want to skim the introductory programming steps. To get ahead, go to the Week 2 Python exercises, read some of The elements of statistical learning or reinforce your own learning by helping less experienced students in the Comments here or on the discussion forum
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: yellow
		  id:: 67beaca2-32f7-4291-bffa-9c48d954f3b2
		  hl-stamp:: 1740549344982
		  collapsed:: true
			- If you haven’t installed Python and an Integrated Development Environment (IDE) yet, you can use this online IDE for experimenting with these basic coding examples but you will need to install Anaconda soon. Instructions are in the previous step.
			  ls-type:: annotation
			  hl-page:: 19
			  hl-color:: yellow
			  id:: 67beacbc-9f3c-401b-b659-8a29d71808fa
			  background-color:: yellow
			  hl-stamp:: 1740549337124
			- Let’s start by exploring some basic features of Python programming. Don’t worry if you are completely new to this
			  ls-type:: annotation
			  hl-page:: 19
			  hl-color:: yellow
			  id:: 67beacc6-d3e1-4007-acb7-488f51895eaf
			  background-color:: yellow
			  hl-stamp:: 1740549340219
	- The traditional ‘Hello world’
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: red
	  id:: 67bead01-bc82-4453-b83a-67eae5f3ad81
	  collapsed:: true
		- Run the following *cell* in your Python IDE (i.e. Jupyter Notebook, which is contained within Anaconda).
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: blue
		  id:: 67bead10-6a0a-4358-992d-b7aa7fee611c
		- Code example 1
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: red
		  id:: 67bead2c-b8c0-4a89-abf5-941196aea9fb
			- hl-page:: 19
			  ls-type:: annotation
			  id:: 67bead44-4702-48af-a9f9-6ae243b21c64
			  hl-color:: purple
			  ```python
			  print("Hello, World!") 
			  print('Hello, World!')
			  
			  # Hello, World!
			  # Hello, World!
			  ```
	- Write a Python code that will print your name.
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: red
	  id:: 67beaf3a-d39f-4061-a883-8d49148d8156
	  collapsed:: true
		- ```python
		  print('Hello, pcramer')
		  ```
	- Inserting Comments
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: red
	  id:: 67beb177-a818-499c-8219-2e1bc4de2d2a
	  collapsed:: true
		- You should insert comments to improve the readability of your program and to remind you what each line of code does. You might think you’ll remember but you won’t. There are three ways to insert comments.
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: blue
		  id:: 67beb17e-04fd-4b23-92e0-7d40f058fec2
		- Code example 2
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: red
		  id:: 67beb18c-a0e8-40a9-bb98-e773c125046a
			- hl-page:: 19
			  ls-type:: annotation
			  id:: 67beb195-c325-4a05-82ce-c093025d6c39
			  hl-color:: purple
			  ```python
			  # This is a one-line comment''' 
			  '''
			  This is a 
			  multi-line comment
			  '''
			  """
			  This is also a 
			  multi-line comment
			  """
			  print("I don't see any comments")
			  
			  # I don't see any comments
			  ```
	- Variables
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: red
	  id:: 67beb6b0-69e2-4a19-9371-43b0609926dc
	  collapsed:: true
		- Variable are containers. They’re like a bowls or cups. You can put a variety of things in them, but the bowl doesn’t change. Variable names in Python can contain letters and numbers. You don’t need to explicitly deﬁne the type of variable. But you can inspect the variable type using the 𝑡𝑦𝑝𝑒()
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: blue
		  id:: 67beb6b5-a3e8-4747-b6f2-54acb8420e29
		- Code example 3
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: red
		  id:: 67beb6c2-f37f-464e-9294-8f060979a6f5
			- hl-page:: 19
			  ls-type:: annotation
			  id:: 67beb6d2-dae5-4145-83d4-5b54f297290d
			  hl-color:: purple
			  ```python
			  x = 10 type(x)
			  
			  # int
			  ```
		- Assign a ﬂoating point number (eg. 1.3) and then a string (eg. “hello”) for 𝑥
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: blue
		  id:: 67beb74e-3ad6-4cdb-b423-84590ec18791
		  hl-stamp:: 1740552023331
	- Lists
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: red
	  id:: 67beb7f2-163a-438a-a231-b08be2a64d21
	  collapsed:: true
		- *List* is the most versatile and common data type in Python. Lists can contain values of different types. The syntax for creating lists in Python is `list_name = [item_0, item_1, …, item_n]`.
		  hl-page:: 19
		  ls-type:: annotation
		  id:: 67beb833-19fb-4e9e-bf06-907ded546a79
		  hl-color:: green
		  hl-stamp:: 1740552259842
		- Code example 4
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: red
		  id:: 67beb862-0aff-40db-99fa-0bc3c8fdf2b4
			- hl-page:: 19
			  ls-type:: annotation
			  id:: 67beb86d-9de5-4d0b-b482-161f691b8aba
			  hl-color:: purple
			  ```python
			  mylist = [1, 5, 2.57, 'abc', 4.09] 
			  print(type(mylist)) # prints the type 
			  print(mylist) # prints the entire list 
			  print("Length of the list is: ", len(mylist))
			  
			  # <class 'list'>
			  # [1, 5, 2.57, 'abc', 4.09] 
			  # Length of the list is: 5
			  ```
		- List indexing starts from $0$ and ends with $−1$. The index of $−1$
		  hl-page:: 19
		  ls-type:: annotation
		  id:: 67beb93e-fbf2-4a49-8c8f-66dd677eccad
		  hl-color:: blue
		- represents the last element.
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: blue
		  id:: 67beb948-8dc7-4cd3-bb89-63e99cf4b4c1
		- Code example 5
		  ls-type:: annotation
		  hl-page:: 19
		  hl-color:: red
		  id:: 67beba66-0fe8-43bc-9c01-a85019622e1a
			- hl-page:: 19
			  ls-type:: annotation
			  id:: 67beba92-4425-40b1-b11d-fcccf890abbe
			  hl-color:: purple
			  ```python
			  # indexing 
			  numbers = [1, 2, 3, 4, 5, 6, 7, 8] 
			  
			  print(numbers[0]) 
			  print(numbers[3]) 
			  print(numbers[-1]) # last element 
			  print(numbers[-2]) # can you guess the result?
			  ```
- Tuple data type
  ls-type:: annotation
  hl-page:: 19
  hl-color:: red
  id:: 67bebbcf-366c-4ab9-93b7-4014ebdd05ce
	- A tuple is like a list, but the items cannot be changed once initiated. Indexing rules are similar to lists.
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: blue
	  id:: 67bebbef-079d-46fd-85eb-ecbf6876fe81
	- Syntax: `tuple_name = (item_1, item_2, …., item_n)`
	  ls-type:: annotation
	  hl-page:: 19
	  hl-color:: blue
	  id:: 67bebbfd-2092-4062-b81f-7641a9fed5b9
- Code example 6
  ls-type:: annotation
  hl-page:: 19
  hl-color:: red
  id:: 67bebc11-8abd-48a6-9482-7dc6002798ea
- hl-page:: 19
  ls-type:: annotation
  id:: 67bebc1a-aadd-4e61-a989-461c69a40b04
  hl-color:: purple
  ```python
  states = ('VIC', 'NSW', 'QLD', 'WA', 'ACT', 'NT', 'TAS', 'SA') 
  print(type(states)) 
  print(states)
  ```